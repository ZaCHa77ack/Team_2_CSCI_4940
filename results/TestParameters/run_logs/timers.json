{
    "name": "root",
    "gauges": {
        "Agent_Controller.Policy.Entropy.mean": {
            "value": 1.1590856313705444,
            "min": 1.1583110094070435,
            "max": 1.4316598176956177,
            "count": 47
        },
        "Agent_Controller.Policy.Entropy.sum": {
            "value": 11610.560546875,
            "min": 11425.580078125,
            "max": 14611.51953125,
            "count": 47
        },
        "Agent_Controller.Step.mean": {
            "value": 469956.0,
            "min": 9995.0,
            "max": 469956.0,
            "count": 47
        },
        "Agent_Controller.Step.sum": {
            "value": 469956.0,
            "min": 9995.0,
            "max": 469956.0,
            "count": 47
        },
        "Agent_Controller.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.16455741226673126,
            "min": -0.23434314131736755,
            "max": 0.6806997656822205,
            "count": 47
        },
        "Agent_Controller.Policy.ExtrinsicValueEstimate.sum": {
            "value": 29.126663208007812,
            "min": -45.22822570800781,
            "max": 119.80315399169922,
            "count": 47
        },
        "Agent_Controller.Losses.PolicyLoss.mean": {
            "value": 0.24219266416597698,
            "min": 0.23756003404646764,
            "max": 0.2522457279626067,
            "count": 47
        },
        "Agent_Controller.Losses.PolicyLoss.sum": {
            "value": 16.95348649161839,
            "min": 16.95348649161839,
            "max": 19.4591441825786,
            "count": 47
        },
        "Agent_Controller.Losses.ValueLoss.mean": {
            "value": 0.4256844527806025,
            "min": 0.08961863962623179,
            "max": 0.67870670687844,
            "count": 47
        },
        "Agent_Controller.Losses.ValueLoss.sum": {
            "value": 29.797911694642178,
            "min": 6.811016611593616,
            "max": 52.26041642963988,
            "count": 47
        },
        "Agent_Controller.Policy.LearningRate.mean": {
            "value": 2.103059013269143e-05,
            "min": 2.103059013269143e-05,
            "max": 0.0002967208125216343,
            "count": 47
        },
        "Agent_Controller.Policy.LearningRate.sum": {
            "value": 0.0014721413092884,
            "min": 0.0014721413092884,
            "max": 0.021536397221201,
            "count": 47
        },
        "Agent_Controller.Policy.Epsilon.mean": {
            "value": 0.10701016571428572,
            "min": 0.10701016571428572,
            "max": 0.19890693714285712,
            "count": 47
        },
        "Agent_Controller.Policy.Epsilon.sum": {
            "value": 7.4907116,
            "min": 7.4907116,
            "max": 14.7080578,
            "count": 47
        },
        "Agent_Controller.Policy.Beta.mean": {
            "value": 0.0005,
            "min": 0.0005,
            "max": 0.0005000000000000001,
            "count": 47
        },
        "Agent_Controller.Policy.Beta.sum": {
            "value": 0.035,
            "min": 0.035,
            "max": 0.04000000000000001,
            "count": 47
        },
        "Agent_Controller.Environment.EpisodeLength.mean": {
            "value": 161.38095238095238,
            "min": 89.58,
            "max": 198.3695652173913,
            "count": 47
        },
        "Agent_Controller.Environment.EpisodeLength.sum": {
            "value": 6778.0,
            "min": 6778.0,
            "max": 12875.0,
            "count": 47
        },
        "Agent_Controller.Environment.CumulativeReward.mean": {
            "value": 1.0930232558139534,
            "min": -0.3898305084745763,
            "max": 1.1,
            "count": 47
        },
        "Agent_Controller.Environment.CumulativeReward.sum": {
            "value": 47.0,
            "min": -29.0,
            "max": 88.0,
            "count": 47
        },
        "Agent_Controller.Policy.ExtrinsicReward.mean": {
            "value": 1.0930232558139534,
            "min": -0.3898305084745763,
            "max": 1.1,
            "count": 47
        },
        "Agent_Controller.Policy.ExtrinsicReward.sum": {
            "value": 47.0,
            "min": -29.0,
            "max": 88.0,
            "count": 47
        },
        "Agent_Controller.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 47
        },
        "Agent_Controller.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 47
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1712632203",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\arceu\\miniconda3\\envs\\mlagents\\Scripts\\mlagents-learn config/Agent_Controller.yaml --run-id=TestParameters",
        "mlagents_version": "1.0.0",
        "mlagents_envs_version": "1.0.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.13.1+cu117",
        "numpy_version": "1.23.1",
        "end_time_seconds": "1712634110"
    },
    "total": 1907.2536129000073,
    "count": 1,
    "self": 0.010222800003248267,
    "children": {
        "run_training.setup": {
            "total": 0.10366249999788124,
            "count": 1,
            "self": 0.10366249999788124
        },
        "TrainerController.start_learning": {
            "total": 1907.1397276000062,
            "count": 1,
            "self": 1.2815945989859756,
            "children": {
                "TrainerController._reset_env": {
                    "total": 8.532523799993214,
                    "count": 1,
                    "self": 8.532523799993214
                },
                "TrainerController.advance": {
                    "total": 1897.2196542010206,
                    "count": 54778,
                    "self": 1.0671322015405167,
                    "children": {
                        "env_step": {
                            "total": 1080.9283992005658,
                            "count": 54778,
                            "self": 1034.180455702779,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 46.027416897937655,
                                    "count": 54778,
                                    "self": 3.438815597226494,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 42.58860130071116,
                                            "count": 52257,
                                            "self": 42.58860130071116
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.7205265998491086,
                                    "count": 54777,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 1799.0180223001225,
                                            "count": 54777,
                                            "is_parallel": true,
                                            "self": 840.284699600772,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0007053000008454546,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.0001331000094069168,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0005721999914385378,
                                                            "count": 10,
                                                            "is_parallel": true,
                                                            "self": 0.0005721999914385378
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 958.7326173993497,
                                                    "count": 54777,
                                                    "is_parallel": true,
                                                    "self": 13.303483100884478,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 9.149520800376195,
                                                            "count": 54777,
                                                            "is_parallel": true,
                                                            "self": 9.149520800376195
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 897.2063355982682,
                                                            "count": 54777,
                                                            "is_parallel": true,
                                                            "self": 897.2063355982682
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 39.07327789982082,
                                                            "count": 54777,
                                                            "is_parallel": true,
                                                            "self": 7.548248695486109,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 31.525029204334714,
                                                                    "count": 547770,
                                                                    "is_parallel": true,
                                                                    "self": 31.525029204334714
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 815.2241227989143,
                            "count": 54777,
                            "self": 1.8410036985587794,
                            "children": {
                                "process_trajectory": {
                                    "total": 141.29040510047344,
                                    "count": 54777,
                                    "self": 141.29040510047344
                                },
                                "_update_policy": {
                                    "total": 672.0927139998821,
                                    "count": 3554,
                                    "self": 111.63552169897594,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 560.4571923009062,
                                            "count": 135090,
                                            "self": 560.4571923009062
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.3999961083754897e-06,
                    "count": 1,
                    "self": 1.3999961083754897e-06
                },
                "TrainerController._save_models": {
                    "total": 0.10595360001025256,
                    "count": 1,
                    "self": 0.01911120000295341,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.08684240000729915,
                            "count": 1,
                            "self": 0.08684240000729915
                        }
                    }
                }
            }
        }
    }
}